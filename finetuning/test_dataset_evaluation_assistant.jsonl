{"questions": {"5c1f4dd0-fd19-4368-bdbb-fb50e3e37f79": "What does a lower Kendall\u2019s \u03c4 in Table 5 indicate about the ranking produced by the metrics?", "b70674cc-fb4f-412e-a2ad-49217f6ce2a3": "To what factor do the authors attribute the differences in retrieved context length across examples?", "560550ae-943d-4a38-9131-c3d6d87581f0": "How are the simulated RAG datasets from Saad-Falcon et al. [32] augmented for evaluation in Table 5?", "1afb2be2-712b-4149-8351-3a98f9e6e5b8": "What metric is used to evaluate the agreement between GPT-4-turbo rankings and the ground truth in the study?", "6cd36c18-ed68-456d-af14-25f3a5400d5b": "What does a higher agreement between GPT-4-turbo rankings and ground truth indicate?", "c5c2af70-7921-4ba2-87de-7d00c25f7c1f": "How is the performance of GPT-4-turbo rankings measured in relation to the ground truth?", "4220a4b8-2269-453e-b863-b06883b42b7b": "What are the Kendall\u2019s Tau binary and continuous values for the datasets NQ, HotpotQA, WoW, and FEVER as shown in the context?", "762e69c7-8c97-49ca-98d5-170b419c6c4a": "What prompt templates are used in the RAG Case Study according to the provided context?", "0a8b15dc-0652-4e18-95de-dde865fce67d": "What should you do if the documents do not provide enough information to answer a user's question?", "77ea3955-d03a-4cc4-8921-69e99962ceda": "Are you allowed to use external knowledge or make up answers when responding to user queries?", "762629a9-87a5-444b-85c7-a5f3f751b8ff": "What is the main topic discussed in the provided context documents?", "057f3491-4c4d-46e1-9312-7197be7567f4": "How does the information in the context documents help answer the given question?", "0549de2f-4194-4211-9329-f27292d9e53c": "What specific results are reported in Table 6 from the RAG Case Study?", "04f06ef6-1604-46b9-ac65-a7f4dc85b16e": "How do the results in Table 6 contribute to the overall findings of the RAG Case Study?", "c8e703fd-d90d-4eea-b3d3-bd50e813f727": "How does the prompt version (no context, short, long) affect the average hallucination percentage (pc hallucinated) for the gpt-4o generation model using the tfidf retriever with k=2?", "2dea004d-92fa-4e0c-962c-836824385fa4": "Which generation model shows higher average utilization when using the tfidf retriever with k=2 and a short prompt version?", "278f3732-0c21-4fac-b875-0431ab8c79cf": "How does the performance of gpt-4o compare to gpt-3.5-turbo-0125 when using tfidf with 2 long + CoT context?", "745281f1-f82d-4d01-a6cf-1979cc233ee3": "What impact does increasing the tfidf parameter from 2 to 4 have on the metrics for both gpt-4o and gpt-3.5-turbo-0125 models?", "dbf55c9a-7e6b-43fb-8285-8d16c31b0d26": "How does the performance of gpt-4o compare to gpt-3.5-turbo-0125 when using the faiss method with short context?", "c7dd6664-795a-4270-8f26-f8c65598b231": "What impact does adding Chain of Thought (CoT) reasoning have on the tfidf method's results for gpt-4o?", "1b3cb70d-07d9-4d9b-8308-a44b9c0a85d0": "How does the performance of gpt-4o compare to gpt-3.5-turbo-0125 when using \"long + CoT\" context with faiss at level 2?", "f77e7f5a-b2d3-48de-8d95-2a2534eddebe": "What impact does the context length (\"no context,\" \"short,\" \"long\") have on the precision and recall metrics for faiss at level 4 using gpt-4o?", "0efb27c8-c65d-41b4-9af6-e4ffda441ae5": "What are the performance differences between the gpt-4o and gpt-3.5-turbo-0125 models when using the \"long + CoT\" approach with faiss?", "b6e66125-b7f0-407a-b1a7-bbc628e4fe90": "How does the inclusion of Chain of Thought (CoT) affect the metrics for the gpt-4o model compared to using \"long\" alone with faiss?", "85d12edb-0c3e-42f3-8bdc-3fa225073216": "What hardware is used to train the DeBERTa model described in the context?", "1844c2a3-7eb5-40b3-8fd4-2f94f9bdbde3": "How many epochs and what learning rates are used during the training of the DeBERTa model?", "b4dd7dae-08be-4e7d-a2b4-41c839216a68": "What steps should be taken to enable JavaScript and cookies in a web browser?", "7f18f3dd-e85e-49b0-8935-5619817c64e0": "Why is enabling JavaScript and cookies necessary to continue on certain websites?"}, "relevant_contexts": {"5c1f4dd0-fd19-4368-bdbb-fb50e3e37f79": ["f4d6e83c-a65a-49e2-9c83-172907dce25c"], "b70674cc-fb4f-412e-a2ad-49217f6ce2a3": ["f4d6e83c-a65a-49e2-9c83-172907dce25c"], "560550ae-943d-4a38-9131-c3d6d87581f0": ["b0a6a11a-09cc-4f94-a2e1-4212af099847"], "1afb2be2-712b-4149-8351-3a98f9e6e5b8": ["b0a6a11a-09cc-4f94-a2e1-4212af099847"], "6cd36c18-ed68-456d-af14-25f3a5400d5b": ["21441df1-1f21-4ff4-bc41-783270af03bf"], "c5c2af70-7921-4ba2-87de-7d00c25f7c1f": ["21441df1-1f21-4ff4-bc41-783270af03bf"], "4220a4b8-2269-453e-b863-b06883b42b7b": ["394301f0-605d-4504-a6c5-8db7aeab32d7"], "762e69c7-8c97-49ca-98d5-170b419c6c4a": ["394301f0-605d-4504-a6c5-8db7aeab32d7"], "0a8b15dc-0652-4e18-95de-dde865fce67d": ["407f0287-2b93-4c33-8a9d-5ffded4ad8f9"], "77ea3955-d03a-4cc4-8921-69e99962ceda": ["407f0287-2b93-4c33-8a9d-5ffded4ad8f9"], "762629a9-87a5-444b-85c7-a5f3f751b8ff": ["4794159d-99cb-4236-865e-350999b0aed5"], "057f3491-4c4d-46e1-9312-7197be7567f4": ["4794159d-99cb-4236-865e-350999b0aed5"], "0549de2f-4194-4211-9329-f27292d9e53c": ["13988b12-e09d-414d-b40c-0ec6fa008f9e"], "04f06ef6-1604-46b9-ac65-a7f4dc85b16e": ["13988b12-e09d-414d-b40c-0ec6fa008f9e"], "c8e703fd-d90d-4eea-b3d3-bd50e813f727": ["db3457ce-6390-4814-87d9-9e1958cb9d45"], "2dea004d-92fa-4e0c-962c-836824385fa4": ["db3457ce-6390-4814-87d9-9e1958cb9d45"], "278f3732-0c21-4fac-b875-0431ab8c79cf": ["74fe15a4-5a2d-4164-83ae-bb81c5c0812e"], "745281f1-f82d-4d01-a6cf-1979cc233ee3": ["74fe15a4-5a2d-4164-83ae-bb81c5c0812e"], "dbf55c9a-7e6b-43fb-8285-8d16c31b0d26": ["e4cdc15a-a224-48e4-8430-4e1abfb396ff"], "c7dd6664-795a-4270-8f26-f8c65598b231": ["e4cdc15a-a224-48e4-8430-4e1abfb396ff"], "1b3cb70d-07d9-4d9b-8308-a44b9c0a85d0": ["78e48559-b9d3-4ad9-a861-35a3cb9263d2"], "f77e7f5a-b2d3-48de-8d95-2a2534eddebe": ["78e48559-b9d3-4ad9-a861-35a3cb9263d2"], "0efb27c8-c65d-41b4-9af6-e4ffda441ae5": ["6c01772c-32bc-4043-8b5a-89c508bf27e9"], "b6e66125-b7f0-407a-b1a7-bbc628e4fe90": ["6c01772c-32bc-4043-8b5a-89c508bf27e9"], "85d12edb-0c3e-42f3-8bdc-3fa225073216": ["e25f0158-b401-4846-a9f9-637bb70ff0ab"], "1844c2a3-7eb5-40b3-8fd4-2f94f9bdbde3": ["e25f0158-b401-4846-a9f9-637bb70ff0ab"], "b4dd7dae-08be-4e7d-a2b4-41c839216a68": ["cf71b2fa-4b2c-4a38-af56-a5164e4630c4"], "7f18f3dd-e85e-49b0-8935-5619817c64e0": ["cf71b2fa-4b2c-4a38-af56-a5164e4630c4"]}, "corpus": {"f4d6e83c-a65a-49e2-9c83-172907dce25c": "produce a different ranking (see lower Kendall\u2019s \u03c4\ud835\udf0f\\tauitalic_\u03c4 in Table 5), which we attribute to the metrics capturing differences in retrieved context length across the different examples.", "b0a6a11a-09cc-4f94-a2e1-4212af099847": "Table 5: Ranking of Simulated RAG Systems. We evaluate GPT-4-turbo annotations on simulated RAG datasets from Saad-Falcon et\u00a0al. [32]. The data from each source are synthetically augmented to create sets with increasing degrees of context relevance (Rel) and answer adherence (Adh). We annotate 500 samples from each set and rank them according to the average context relevance and answer adherence metrics. We report Kendall\u2019s tau to evaluate the agreement between GPT-4-turbo rankings and ground", "21441df1-1f21-4ff4-bc41-783270af03bf": "agreement between GPT-4-turbo rankings and ground truth (higher is better).", "394301f0-605d-4504-a6c5-8db7aeab32d7": "NQ\nHotpotQA\nWoW\nFEVER\n\n\n\nRel\nAdh\nRel\nAdh\nRel\nAdh\nRel\nAdh\n\n\n\n\nKendall\u2019s Tau binary\n1.0\n0.83\n0.87\n1.0\n1.0\n0.89\n1.0\n0.78\n\n\nKendall\u2019s Tau continuous\n0.94\n-\n0.73\n-\n1.0\n-\n0.77\n-\n\n\n\n\n\n\n\n\n7.7 RAG Case Study\n\nWe use the following prompt templates for the RAG Case Study:\n\n\nNO CONTEXT:\n\n{question}\n\n\n\nSHORT:\n\nAnswer the question using the provided context.\n\nContext:\n{documents}\n\nQuestion: {question}\n\n\n\nLONG:", "407f0287-2b93-4c33-8a9d-5ffded4ad8f9": "Question: {question}\n\n\n\nLONG:\n\nYou are a chatbot providing answers to user queries. You will be given one or more context documents, and a question. \\\nUse the information in the documents to answer the question.\n\nIf the documents do not provide enough information for you to answer the question, then say \\\n\"The documents are missing some of the information required to answer the question.\" Don\u2019t quote any external knowledge that is \\\nnot in the documents. Don\u2019t try to make up an answer.", "4794159d-99cb-4236-865e-350999b0aed5": "Context Documents:\n{documents}\n\nQuestion: {question}\n\n\n\nLONG + CoT:\n\nYou are a chatbot providing answers to user queries. You will be given one or more context documents, and a question. \\\nUse the information in the documents to answer the question.", "13988b12-e09d-414d-b40c-0ec6fa008f9e": "If the documents do not provide enough information for you to answer the question, then say \\\n\"The documents are missing some of the information required to answer the question.\" Don\u2019t quote any external knowledge that is \\\nnot in the documents. Don\u2019t try to make up an answer.\n\nThink step by step and explain your reasoning, quoting the documents when necessary.\n\nContext Documents:\n{documents}\n\nQuestion: {question}\n\n\n\nTable 6 reports comprehensive results from the RAG Case Study.", "db3457ce-6390-4814-87d9-9e1958cb9d45": "Table 6: RAG Case Study Results.\n\n\n\nretriever\nk\nprompt version\ngeneration model\nave relevance\nave utilization\nave completeness\npc hallucinated\n\n\n\n\ntfidf\n2\nno context\ngpt-3.5-turbo-0125\n0.65\n0.30\n0.53\n0.94\n\n\ntfidf\n2\nno context\ngpt-4o\n0.66\n0.45\n0.70\n0.95\n\n\ntfidf\n2\nshort\ngpt-3.5-turbo-0125\n0.62\n0.43\n0.72\n0.19\n\n\ntfidf\n2\nshort\ngpt-4o\n0.66\n0.54\n0.81\n0.29\n\n\ntfidf\n2\nlong\ngpt-3.5-turbo-0125\n0.62\n0.43\n0.71\n0.04\n\n\ntfidf\n2\nlong\ngpt-4o\n0.66\n0.35\n0.57\n0.08", "74fe15a4-5a2d-4164-83ae-bb81c5c0812e": "tfidf\n2\nlong\ngpt-4o\n0.66\n0.35\n0.57\n0.08\n\n\ntfidf\n2\nlong + CoT\ngpt-3.5-turbo-0125\n0.65\n0.53\n0.82\n0.13\n\n\ntfidf\n2\nlong + CoT\ngpt-4o\n0.63\n0.50\n0.78\n0.04\n\n\ntfidf\n4\nno context\ngpt-3.5-turbo-0125\n0.46\n0.22\n0.53\n0.86\n\n\ntfidf\n4\nno context\ngpt-4o\n0.45\n0.29\n0.65\n0.86\n\n\ntfidf\n4\nshort\ngpt-3.5-turbo-0125\n0.43\n0.29\n0.67\n0.18\n\n\ntfidf\n4\nshort\ngpt-4o\n0.47\n0.38\n0.78\n0.13\n\n\ntfidf\n4\nlong\ngpt-3.5-turbo-0125\n0.45\n0.28\n0.64\n0.05\n\n\ntfidf\n4\nlong\ngpt-4o\n0.48\n0.28\n0.60\n0.05", "e4cdc15a-a224-48e4-8430-4e1abfb396ff": "tfidf\n4\nlong\ngpt-4o\n0.48\n0.28\n0.60\n0.05\n\n\ntfidf\n4\nlong + CoT\ngpt-3.5-turbo-0125\n0.44\n0.33\n0.72\n0.10\n\n\ntfidf\n4\nlong + CoT\ngpt-4o\n0.49\n0.36\n0.73\n0.02\n\n\nfaiss\n2\nno context\ngpt-3.5-turbo-0125\n0.81\n0.40\n0.50\n0.94\n\n\nfaiss\n2\nno context\ngpt-4o\n0.81\n0.53\n0.66\n0.87\n\n\nfaiss\n2\nshort\ngpt-3.5-turbo-0125\n0.75\n0.55\n0.72\n0.07\n\n\nfaiss\n2\nshort\ngpt-4o\n0.82\n0.72\n0.86\n0.11\n\n\nfaiss\n2\nlong\ngpt-3.5-turbo-0125\n0.78\n0.58\n0.71\n0.04\n\n\nfaiss\n2\nlong\ngpt-4o\n0.82\n0.52\n0.62\n0.10", "78e48559-b9d3-4ad9-a861-35a3cb9263d2": "faiss\n2\nlong\ngpt-4o\n0.82\n0.52\n0.62\n0.10\n\n\nfaiss\n2\nlong + CoT\ngpt-3.5-turbo-0125\n0.81\n0.64\n0.76\n0.07\n\n\nfaiss\n2\nlong + CoT\ngpt-4o\n0.83\n0.69\n0.82\n0.04\n\n\nfaiss\n4\nno context\ngpt-3.5-turbo-0125\n0.58\n0.27\n0.47\n0.88\n\n\nfaiss\n4\nno context\ngpt-4o\n0.58\n0.36\n0.60\n0.79\n\n\nfaiss\n4\nshort\ngpt-3.5-turbo-0125\n0.53\n0.31\n0.59\n0.14\n\n\nfaiss\n4\nshort\ngpt-4o\n0.58\n0.47\n0.78\n0.07\n\n\nfaiss\n4\nlong\ngpt-3.5-turbo-0125\n0.54\n0.33\n0.61\n0.08\n\n\nfaiss\n4\nlong\ngpt-4o\n0.61\n0.32\n0.52\n0.09", "6c01772c-32bc-4043-8b5a-89c508bf27e9": "faiss\n4\nlong\ngpt-4o\n0.61\n0.32\n0.52\n0.09\n\n\nfaiss\n4\nlong + CoT\ngpt-3.5-turbo-0125\n0.58\n0.42\n0.71\n0.09\n\n\nfaiss\n4\nlong + CoT\ngpt-4o\n0.60\n0.47\n0.76\n0.05\n\n\n\n\n\n\n\n7.8 DeBERTa model training", "e25f0158-b401-4846-a9f9-637bb70ff0ab": "7.8 DeBERTa model training\n\nWe train the model on a Google Cloud Platform A-100 GPU instance for 3 epochs with initial learning rate 5\u22126superscript565^{-6}5 start_POSTSUPERSCRIPT - 6 end_POSTSUPERSCRIPT for the base model layers and 2\u22125superscript252^{-5}2 start_POSTSUPERSCRIPT - 5 end_POSTSUPERSCRIPT for the heads, with warmup and a linear decay rate.\n\n\n\n\n\n\nGenerated  on Thu Jan 16 10:04:53 2025 by LaTeXML", "cf71b2fa-4b2c-4a38-af56-a5164e4630c4": "Just a moment...Enable JavaScript and cookies to continue"}}